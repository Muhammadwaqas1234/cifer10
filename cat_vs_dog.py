# -*- coding: utf-8 -*-
"""cat_vs_dog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jYQv70DJxEStrgIdDFxJj-iXX1k-zTIA
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

x_train = x_train / 255.0
x_test  = x_test / 255.0

from tensorflow.keras import Input

model = models.Sequential([
    Input(shape=(32,32,3)),

    layers.Conv2D(32, (3,3), padding="same"),
    layers.BatchNormalization(),
    layers.ReLU(),

    layers.Conv2D(32, (3,3), padding="same"),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.MaxPooling2D(),
    layers.Dropout(0.25),

    layers.Conv2D(64, (3,3), padding="same"),
    layers.BatchNormalization(),
    layers.ReLU(),

    layers.Conv2D(64, (3,3), padding="same"),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.MaxPooling2D(),
    layers.Dropout(0.30),

    layers.Conv2D(128, (3,3), padding="same"),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.MaxPooling2D(),
    layers.Dropout(0.40),

    layers.Flatten(),

    layers.Dense(128, activation="relu",
                 kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    layers.BatchNormalization(),
    layers.Dropout(0.4),

    layers.Dense(10, activation="softmax")
])

optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1
)

early_stop = EarlyStopping(
    monitor='val_loss', patience=6, restore_best_weights=True, verbose=1
)

model.compile(
    optimizer=optimizer,
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=5,
    batch_size=64,
    callbacks=[lr_scheduler, early_stop]
)
test_loss, test_acc = model.evaluate(x_test, y_test)
print("Test Accuracy:", test_acc)

import numpy as np
import matplotlib.pyplot as plt



# CIFAR-10 class names
class_names = [
    "airplane", "automobile", "bird", "cat", "deer",
    "dog", "frog", "horse", "ship", "truck"
]

# -----------------------------
# Pick 10 random images
# -----------------------------
indices = np.random.choice(len(x_test), size=10, replace=False)
images = x_test[indices]
true_labels = y_test[indices]

# -----------------------------
# Predict using the trained model
# -----------------------------
y_pred = model.predict(images)  # model is your trained CNN
pred_labels = y_pred.argmax(axis=1)

# -----------------------------
# Plot images with True & Predicted labels
# -----------------------------
plt.figure(figsize=(15,5))
for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(images[i])
    plt.title(f"True: {class_names[true_labels[i][0]]}\nPred: {class_names[pred_labels[i]]}")
    plt.axis('off')
plt.show()

import matplotlib.pyplot as plt

# Plot Accuracy
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12,5))

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import tensorflow as tf

# Load CIFAR-10 classes
class_names = [
    "airplane", "automobile", "bird", "cat", "deer",
    "dog", "frog", "horse", "ship", "truck"
]

# Step 1: Predict on test set
y_pred_probs = model.predict(x_test)          # model outputs probabilities
y_pred = np.argmax(y_pred_probs, axis=1)     # get predicted class labels
y_true = y_test.flatten()                     # true labels

# Step 2: Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Step 3: Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
plt.figure(figsize=(10,8))
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.title("CIFAR-10 Confusion Matrix")
plt.show()